{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Disaster Tweet Classifier with DistilBERT\n",
    "\n",
    "The purpose of this model is to determine whether a given Tweet is about a real diaster (war, flood, famine, etc.) or benign. For example, the Tweet \"the sky looks beutifully ablaze tonight\" likelly does not refer to a real fire. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Three people died from the heat wave so far</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Haha South Tampa is getting flooded hah- WAIT ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>#raining #flooding #Florida #TampaBay #Tampa 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>#Flood in Bago Myanmar #We arrived Bago</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Damage to school bus on 80 in multi car crash ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What's up man?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I love fruits</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Summer is lovely</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>My car is so fast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What a goooooooaaaaaal!!!!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  target\n",
       "0   Our Deeds are the Reason of this #earthquake M...       1\n",
       "1              Forest fire near La Ronge Sask. Canada       1\n",
       "2   All residents asked to 'shelter in place' are ...       1\n",
       "3   13,000 people receive #wildfires evacuation or...       1\n",
       "4   Just got sent this photo from Ruby #Alaska as ...       1\n",
       "5   #RockyFire Update => California Hwy. 20 closed...       1\n",
       "6   #flood #disaster Heavy rain causes flash flood...       1\n",
       "7   I'm on top of the hill and I can see a fire in...       1\n",
       "8   There's an emergency evacuation happening now ...       1\n",
       "9   I'm afraid that the tornado is coming to our a...       1\n",
       "10        Three people died from the heat wave so far       1\n",
       "11  Haha South Tampa is getting flooded hah- WAIT ...       1\n",
       "12  #raining #flooding #Florida #TampaBay #Tampa 1...       1\n",
       "13            #Flood in Bago Myanmar #We arrived Bago       1\n",
       "14  Damage to school bus on 80 in multi car crash ...       1\n",
       "15                                     What's up man?       0\n",
       "16                                      I love fruits       0\n",
       "17                                   Summer is lovely       0\n",
       "18                                  My car is so fast       0\n",
       "19                       What a goooooooaaaaaal!!!!!!       0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read from CSV\n",
    "dataset = pd.read_csv(\"./data/train.csv\")\n",
    "\n",
    "# Drop (potentially) unnecessary columns. These may be useful, but I'm not quite ready to work with missing data.\n",
    "dataset = dataset.drop([\"id\", \"keyword\", \"location\"], axis=1)\n",
    "dataset.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the count of each label. Posative indicates that the tweet is about a disaster.\n",
    "posative_count = dataset[dataset[\"target\"] == 1].shape[0]\n",
    "negative_count = dataset[dataset[\"target\"] == 0].shape[0]\n",
    "\n",
    "plt.bar(\"Non-Disaster\",negative_count,0.9, label=\"Non-Disaster\")\n",
    "plt.bar(\"Disaster\",posative_count,0.9, label=\"Disaster\")\n",
    "plt.ylabel('Number of Examples')\n",
    "plt.title('Proportion of Examples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune Pretrained Model for Inference \n",
    "\n",
    "Below, I use the HuggingFace `transformers` library to fine-tune DistilBERT on the tweets dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from datasets import load_dataset, Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at /home/kyle/.cache/huggingface/transformers/4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at /home/kyle/.cache/huggingface/transformers/83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at /home/kyle/.cache/huggingface/transformers/d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at /home/kyle/.cache/huggingface/transformers/4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at /home/kyle/.cache/huggingface/transformers/4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 25.98ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 6090\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1523\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init tokenizer for converting text to numbers\n",
    "model_path = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# In order to add padding on a batch-level rather than a dataset level, add dynamic padding using a data \n",
    "# collator. This will add padding to the maximum input in a batch rather than the entire \n",
    "# data set which saves computation. \n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Read data from CSV, embed, and split into test and train\n",
    "raw_dataset = Dataset.from_pandas(dataset)\n",
    "raw_dataset = raw_dataset.rename_column(\"target\", \"labels\")\n",
    "raw_dataset = raw_dataset.map(lambda example: tokenizer(example[\"text\"]), batched=True)\n",
    "raw_dataset = raw_dataset.with_format(\"torch\")\n",
    "formatted_datasets = raw_dataset.train_test_split(0.2)\n",
    "\n",
    "# Show Output\n",
    "formatted_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at /home/kyle/.cache/huggingface/transformers/4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at /home/kyle/.cache/huggingface/transformers/8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Device Type: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Running on Device Type: {device.type}\")\n",
    "\n",
    "training_arguments = TrainingArguments(\"test-trainer\")\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_arguments,\n",
    "    train_dataset=formatted_datasets[\"train\"],\n",
    "    eval_dataset=formatted_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the Training/Fine-Tuning Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6090\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2286\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'numpy.str_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/kyle/src/repos/disaster-tweet-classifier/transformer.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/kyle/src/repos/disaster-tweet-classifier/transformer.ipynb#ch0000016vscode-remote?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/transformers/trainer.py:1317\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/transformers/trainer.py?line=1311'>1312</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/transformers/trainer.py?line=1313'>1314</a>\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/transformers/trainer.py?line=1314'>1315</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/transformers/trainer.py?line=1315'>1316</a>\u001b[0m )\n\u001b[0;32m-> <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/transformers/trainer.py?line=1316'>1317</a>\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/transformers/trainer.py?line=1317'>1318</a>\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/transformers/trainer.py?line=1318'>1319</a>\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/transformers/trainer.py?line=1319'>1320</a>\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/transformers/trainer.py?line=1320'>1321</a>\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/transformers/trainer.py?line=1321'>1322</a>\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/transformers/trainer.py:1528\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/transformers/trainer.py?line=1524'>1525</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_rng_state(resume_from_checkpoint)\n\u001b[1;32m   <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/transformers/trainer.py?line=1526'>1527</a>\u001b[0m step \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m-> <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/transformers/trainer.py?line=1527'>1528</a>\u001b[0m \u001b[39mfor\u001b[39;00m step, inputs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/transformers/trainer.py?line=1528'>1529</a>\u001b[0m \n\u001b[1;32m   <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/transformers/trainer.py?line=1529'>1530</a>\u001b[0m     \u001b[39m# Skip past any already trained steps if resuming training\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/transformers/trainer.py?line=1530'>1531</a>\u001b[0m     \u001b[39mif\u001b[39;00m steps_trained_in_current_epoch \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/transformers/trainer.py?line=1531'>1532</a>\u001b[0m         steps_trained_in_current_epoch \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=568'>569</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=569'>570</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=570'>571</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=571'>572</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/arrow_dataset.py:2124\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/arrow_dataset.py?line=2121'>2122</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):  \u001b[39m# noqa: F811\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/arrow_dataset.py?line=2122'>2123</a>\u001b[0m     \u001b[39m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/arrow_dataset.py?line=2123'>2124</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem(\n\u001b[1;32m   <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/arrow_dataset.py?line=2124'>2125</a>\u001b[0m         key,\n\u001b[1;32m   <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/arrow_dataset.py?line=2125'>2126</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/arrow_dataset.py:2109\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/arrow_dataset.py?line=2106'>2107</a>\u001b[0m formatter \u001b[39m=\u001b[39m get_formatter(format_type, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures, decoded\u001b[39m=\u001b[39mdecoded, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mformat_kwargs)\n\u001b[1;32m   <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/arrow_dataset.py?line=2107'>2108</a>\u001b[0m pa_subtable \u001b[39m=\u001b[39m query_table(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data, key, indices\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indices \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indices \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/arrow_dataset.py?line=2108'>2109</a>\u001b[0m formatted_output \u001b[39m=\u001b[39m format_table(\n\u001b[1;32m   <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/arrow_dataset.py?line=2109'>2110</a>\u001b[0m     pa_subtable, key, formatter\u001b[39m=\u001b[39;49mformatter, format_columns\u001b[39m=\u001b[39;49mformat_columns, output_all_columns\u001b[39m=\u001b[39;49moutput_all_columns\n\u001b[1;32m   <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/arrow_dataset.py?line=2110'>2111</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/arrow_dataset.py?line=2111'>2112</a>\u001b[0m \u001b[39mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/formatting.py:532\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/formatting.py?line=529'>530</a>\u001b[0m python_formatter \u001b[39m=\u001b[39m PythonFormatter(features\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/formatting.py?line=530'>531</a>\u001b[0m \u001b[39mif\u001b[39;00m format_columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/formatting.py?line=531'>532</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m formatter(pa_table, query_type\u001b[39m=\u001b[39;49mquery_type)\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/formatting.py?line=532'>533</a>\u001b[0m \u001b[39melif\u001b[39;00m query_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcolumn\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/formatting.py?line=533'>534</a>\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m~/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/formatting.py:281\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/formatting.py?line=278'>279</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pa_table: pa\u001b[39m.\u001b[39mTable, query_type: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/formatting.py?line=279'>280</a>\u001b[0m     \u001b[39mif\u001b[39;00m query_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/formatting.py?line=280'>281</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_row(pa_table)\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/formatting.py?line=281'>282</a>\u001b[0m     \u001b[39melif\u001b[39;00m query_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcolumn\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/formatting.py?line=282'>283</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat_column(pa_table)\n",
      "File \u001b[0;32m~/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:58\u001b[0m, in \u001b[0;36mTorchFormatter.format_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m     <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py?line=55'>56</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat_row\u001b[39m(\u001b[39mself\u001b[39m, pa_table: pa\u001b[39m.\u001b[39mTable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[1;32m     <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py?line=56'>57</a>\u001b[0m     row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy_arrow_extractor()\u001b[39m.\u001b[39mextract_row(pa_table)\n\u001b[0;32m---> <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py?line=57'>58</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrecursive_tensorize(row)\n",
      "File \u001b[0;32m~/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:54\u001b[0m, in \u001b[0;36mTorchFormatter.recursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py?line=52'>53</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecursive_tensorize\u001b[39m(\u001b[39mself\u001b[39m, data_struct: \u001b[39mdict\u001b[39m):\n\u001b[0;32m---> <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py?line=53'>54</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m map_nested(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recursive_tensorize, data_struct, map_list\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/utils/py_utils.py:351\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/utils/py_utils.py?line=348'>349</a>\u001b[0m     num_proc \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/utils/py_utils.py?line=349'>350</a>\u001b[0m \u001b[39mif\u001b[39;00m num_proc \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(iterable) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m num_proc:\n\u001b[0;32m--> <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/utils/py_utils.py?line=350'>351</a>\u001b[0m     mapped \u001b[39m=\u001b[39m [\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/utils/py_utils.py?line=351'>352</a>\u001b[0m         _single_map_nested((function, obj, types, \u001b[39mNone\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/utils/py_utils.py?line=352'>353</a>\u001b[0m         \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(iterable, disable\u001b[39m=\u001b[39mdisable_tqdm, desc\u001b[39m=\u001b[39mdesc)\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/utils/py_utils.py?line=353'>354</a>\u001b[0m     ]\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/utils/py_utils.py?line=354'>355</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/utils/py_utils.py?line=355'>356</a>\u001b[0m     split_kwds \u001b[39m=\u001b[39m []  \u001b[39m# We organize the splits ourselve (contiguous splits)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/utils/py_utils.py:352\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/utils/py_utils.py?line=348'>349</a>\u001b[0m     num_proc \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/utils/py_utils.py?line=349'>350</a>\u001b[0m \u001b[39mif\u001b[39;00m num_proc \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(iterable) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m num_proc:\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/utils/py_utils.py?line=350'>351</a>\u001b[0m     mapped \u001b[39m=\u001b[39m [\n\u001b[0;32m--> <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/utils/py_utils.py?line=351'>352</a>\u001b[0m         _single_map_nested((function, obj, types, \u001b[39mNone\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m))\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/utils/py_utils.py?line=352'>353</a>\u001b[0m         \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(iterable, disable\u001b[39m=\u001b[39mdisable_tqdm, desc\u001b[39m=\u001b[39mdesc)\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/utils/py_utils.py?line=353'>354</a>\u001b[0m     ]\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/utils/py_utils.py?line=354'>355</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/utils/py_utils.py?line=355'>356</a>\u001b[0m     split_kwds \u001b[39m=\u001b[39m []  \u001b[39m# We organize the splits ourselve (contiguous splits)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/utils/py_utils.py:288\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/utils/py_utils.py?line=285'>286</a>\u001b[0m \u001b[39m# Singleton first to spare some computation\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/utils/py_utils.py?line=286'>287</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, types):\n\u001b[0;32m--> <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/utils/py_utils.py?line=287'>288</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m function(data_struct)\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/utils/py_utils.py?line=289'>290</a>\u001b[0m \u001b[39m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/utils/py_utils.py?line=290'>291</a>\u001b[0m \u001b[39mif\u001b[39;00m rank \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m logging\u001b[39m.\u001b[39mget_verbosity() \u001b[39m<\u001b[39m logging\u001b[39m.\u001b[39mWARNING:\n",
      "File \u001b[0;32m~/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:51\u001b[0m, in \u001b[0;36mTorchFormatter._recursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py?line=48'>49</a>\u001b[0m     \u001b[39mif\u001b[39;00m data_struct\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mobject:  \u001b[39m# pytorch tensors cannot be instantied from an array of objects\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py?line=49'>50</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecursive_tensorize(substruct) \u001b[39mfor\u001b[39;00m substruct \u001b[39min\u001b[39;00m data_struct]\n\u001b[0;32m---> <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py?line=50'>51</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tensorize(data_struct)\n",
      "File \u001b[0;32m~/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:43\u001b[0m, in \u001b[0;36mTorchFormatter._tensorize\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py?line=39'>40</a>\u001b[0m \u001b[39melif\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(value\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mfloating):\n\u001b[1;32m     <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py?line=40'>41</a>\u001b[0m     default_dtype \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m: torch\u001b[39m.\u001b[39mfloat32}\n\u001b[0;32m---> <a href='file:///home/kyle/miniconda3/envs/disaster-tweet-classifier-env/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py?line=42'>43</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mtensor(value, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdefault_dtype, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtorch_tensor_kwargs})\n",
      "\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'numpy.str_'"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bed1c0c4dec85a904206baf43aa94359ab21b6b8032fc9ee47d5e9164a02932c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('disaster-tweet-classifier-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
